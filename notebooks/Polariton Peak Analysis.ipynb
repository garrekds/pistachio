{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Polariton Peak Analysis\n",
    "\n",
    "Author: Garrek Stemo\n",
    "\n",
    "Affiliation: Nara Institute of Science and Technology\n",
    "\n",
    "Date created: August 31, 2020\n",
    "\n",
    "Date updated: November 20, 2020\n",
    "\n",
    "This is an interactive notebook for analyzing angle-resolved FTIR cavity-coupled molecular spectra. Interactivity with a dataset is crucials for deciding on a model and visually inspecting the fits. The notebook uses the [lmfit](https://lmfit.github.io/lmfit-py/) package, which is a wrapper for SciPy's optimize method. It allows the user to easily define and modify a model, making it well-adapted to an interactive programming scheme like this one. Lmfit comes with almost all of the fitting functions one might need to perform analysis, but I have included additional functions in a custom `pmath.py` module, including some asymmetric peak models. Functions to pull data from FTIR experiments and transfer matrix simulations are in the `data_io.py` module. These functions assume the files are named a certain way and are in a particular format, so check out that module for more detail or you can write your own. This routine formats the results in a pandas DataFrame, which is exported as a csv. The main text file for storing Rabi splitting and related metadata is an integral part of the I/O and analysis. It is also loaded as a pandas DataFrame: a central part of the data organization scheme for this research."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "We use the matplotlib widgets framework to generate interactive plots. Make sure you have the appropriate dependencies installed, like nodejs, Jupyter lab extensions, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import signal\n",
    "from scipy import optimize\n",
    "import lmfit as lm\n",
    "from ruamel_yaml import YAML\n",
    "import data_io\n",
    "import material_properties as mp\n",
    "import pmath\n",
    "\n",
    "yaml = YAML()\n",
    "sns.set_theme(context='notebook', style='whitegrid', palette='dark')\n",
    "%matplotlib widget"
   ]
  },
  {
   "source": [
    "## Load Data\n",
    "\n",
    "Assign `data_directory` the path to a directory containing your angle-resolved data. Each .csv data file must contain `deg##.##_` where the `##.##` is an angle (e.g. 5_, 5.0_, 05.00_, etc.). The underscore is necessary, since the program uses this to distinguish the angle information from the rest of the file name."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use sample to reference this data set throughout the analytical flow\n",
    "\n",
    "data_directory = '/path/to/angle/resolved/data/directory/'\n",
    "angle_data, absorbance_data = data_io.get_angle_data_from_dir(data_directory)\n",
    "\n",
    "print('Loading data from:')\n",
    "print(data_directory, '\\n')\n",
    "print('Angles in range: [', angle_data[0][0], ',', angle_data[-1][0], ']')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up your data for fitting\n",
    "\n",
    "Limit the frequency axis bounds using a single (usually the first, or lowest angle) spectrum. Use these initial tools to zoom around your data and truncate (the bounds are applied globally) to isolate the peaks you want to fit. This is a crucial step, since if there are other peaks in your data that are not included in your model, the fit will be poor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose which angle spectrum and subrange to examine\n",
    "\n",
    "angle_index = 0\n",
    "\n",
    "lower_bound = 500\n",
    "upper_bound = 8000\n",
    "spectrum = angle_data[angle_index]\n",
    "angle, wavenumber_O, transmittance_O = spectrum\n",
    "mask = (wavenumber_O >= lower_bound) & (wavenumber_O <= upper_bound)\n",
    "\n",
    "# Plot the selected spectrum or a subrange\n",
    "fig1, ax = plt.subplots()\n",
    "\n",
    "ax.plot(wavenumber_O[mask], transmittance_O[mask])\n",
    "\n",
    "ax.set_title(\"Spectrum subrange for {} degrees\".format(np.round(angle, 2)))\n",
    "ax.set_xlabel(r'Wavenumber (cm$^{-1}$)')\n",
    "ax.set_ylabel('Transmittance %')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Model and Parameters\n",
    "\n",
    "Now test the fitting functions available in `pmath.py` or lmfit to find the one you would like to use. The lmfit package has lots of built-in functions. You can use these, fitting functions in pmath, or your own. This is the model you should use to fit spectra for all the other angles in this angle-resolved dataset. Perform the initial fit for the first data set and plot the results before fitting all data sets (residuals are also included in the lmfit package, conveniently). You can decide if you need to adjust your initial guesses or the model. You can test how well the model performs for any angle in your data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the model, make initial guesses for the fit parameters, and apply constraints.\n",
    "\n",
    "frequency = wavenumber_O[mask]\n",
    "y = transmittance_O[mask]\n",
    "\n",
    "model = lm.models.LorentzianModel(prefix='l1_') + lm.models.LorentzianModel(prefix='l2_')\n",
    "result = model.fit(y, x=frequency, l1_amplitude=1, l1_center=1, l1_sigma=1.0,\n",
    "                               l2_amplitude=1, l2_center=1, l2_sigma=1.0)\n",
    "\n",
    "l1_center = np.round(result.params['l1_center'].value, 2)\n",
    "l2_center = np.round(result.params['l2_center'].value, 2)\n",
    "peak_diff = np.round(np.abs(l1_center - l2_center), 2)\n",
    "\n",
    "result.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the numerical results from this fit\n",
    "\n",
    "print(result.params.pretty_print())\n",
    "print('Peak difference: {} - {} = {}'.format(l2_center, l1_center, peak_diff))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatically Fit Peaks From Multiple Data Sets\n",
    "\n",
    "Now that we have a good fit for the first spectrum, go through and fit the rest, using the results from this first spectrum as the initial guess for the next set, and so on.\n",
    "\n",
    "Afterwards, we should inspect the results to make sure the fitting procedure worked. It's not feasible to inspect *every* spectrum for large data sets (I won't stop you!), but you can sample as many as you like and see what they look like by changing the `examine_spectrum` index and generating a plot for the raw data (blue dots), the best fit (red), and the initial fit (black dashed line). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a fitting procedure\n",
    "\n",
    "Once this is set, you don't have to run this cell anymore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_sets(data_sets, model_func, guess, lbound, ubound):\n",
    "    \"\"\"\n",
    "    Fits all data according to a given model. Model and guess follow lmfit framework.\n",
    "    \"\"\"\n",
    "    guess = guess\n",
    "    results_list = []\n",
    "    xy_data = []\n",
    "    num_sets = len(data_sets)\n",
    "    for i in range(num_sets):\n",
    "        angle = data_sets[i][0]\n",
    "        mask = (wavenumber_O >= lbound) & (wavenumber_O <= ubound)\n",
    "        x_data = data_sets[i][1][mask]\n",
    "        y_data =data_sets[i][2][mask]\n",
    "        result = model_func.fit(y_data, x=x_data,\n",
    "                                l1_amplitude=guess['l1_amplitude'],\n",
    "                                l1_center=guess['l1_center'],\n",
    "                                l1_sigma=guess['l1_sigma'],\n",
    "                                l2_amplitude=guess['l2_amplitude'],\n",
    "                                l2_center=guess['l2_center'],\n",
    "                                l2_sigma=guess['l2_sigma'])\n",
    "\n",
    "        results_list.append(result)\n",
    "        xy_data.append((angle, x_data, y_data))\n",
    "        guess = result.values\n",
    "    return results_list, xy_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze all angle-resolved data and Visualize the Results\n",
    "\n",
    "This will run through all of the angles and fit them using the model defined earlier. Here you can select a subset of data to fit if you don't want to apply the fit to every spectrum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = wavenumber_O[mask]\n",
    "intensity = transmittance_O[mask]\n",
    "sets_to_fit = angle_data[:-1]\n",
    "fit_lbound = 500\n",
    "fit_ubound = 8000\n",
    "\n",
    "initial_result = model.fit(y, x=freq, l1_amplitude=1, l1_center=1, l1_sigma=1.0,\n",
    "                               l2_amplitude=1, l2_center=1, l2_sigma=1.0)\n",
    "\n",
    "set_results, set_xy = fit_sets(sets_to_fit, model, initial_result.values, fit_lbound, fit_ubound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change examine_spectrum to see a specific data set.\n",
    "\n",
    "examine_spectrum = 10\n",
    "result = set_results[examine_spectrum]\n",
    "print(result.params.pretty_print())\n",
    "\n",
    "angle, wavenumber, transmittance = set_xy[examine_spectrum]\n",
    "# mask = (wavenumber >= lower_bound) & (wavenumber <= upper_bound)\n",
    "\n",
    "fig3, ax = plt.subplots()\n",
    "\n",
    "ax.plot(wavenumber, transmittance, 'bo', markersize=3, label='raw data')\n",
    "ax.plot(wavenumber, result.init_fit, 'k--', label='initial fit')\n",
    "ax.plot(wavenumber, result.best_fit, 'r-', label='best fit')\n",
    "\n",
    "ax.set_title(\"Spectrum for {} degrees\".format(np.round(angle, 1)))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dispersion Relation\n",
    "\n",
    "Now we plot the peak positions from the fitting procedure as a function of cavity angle and fit the polariton eigenenergies to the upper and lower polariton curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig4, ax = plt.subplots()\n",
    "\n",
    "theta = []\n",
    "LP = []\n",
    "UP = []\n",
    "\n",
    "for i in np.arange(len(set_results)):\n",
    "    theta.append(set_xy[i][0])\n",
    "    LP.append(set_results[i].params['l1_center'].value)\n",
    "    UP.append(set_results[i].params['l2_center'].value)\n",
    "    \n",
    "ax.scatter(theta, LP)\n",
    "ax.scatter(theta, UP)\n",
    "ax.set_xlabel(r'$\\theta$ (degrees)')\n",
    "ax.set_ylabel(r'Wavenumber (cm$^{-1}$)')\n",
    "ax.set_title('Dispersion Relation')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "## Find Rabi splitting using least squares fit on dispersion data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = [1, 1, 1, 1]    # Initial guess\n",
    "splitting_fit = pmath.splitting_least_squares(x0, theta, LP, UP)\n",
    "E0, Ev, Rabi, n_eff = splitting_fit.x\n",
    "\n",
    "print('E0 =', E0)\n",
    "print('Ev =', Ev)\n",
    "print('Splitting =', Rabi)\n",
    "print('n_eff =', n_eff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_plot = np.linspace(0, 30, 100)\n",
    "theta_rad = theta_plot * (np.pi / 180)\n",
    "\n",
    "En = pmath.coupled_energies(theta_rad, E0, Ev, Rabi, n_eff, branch=0)\n",
    "Ep = pmath.coupled_energies(theta_rad, E0, Ev, Rabi, n_eff, branch=1)\n",
    "E_ph = pmath.cavity_mode_energy(theta_rad, E0, n_eff)\n",
    "E_v = np.full(len(theta_plot), Ev)\n",
    "\n",
    "fig10, ax = plt.subplots()\n",
    "\n",
    "ax.plot(theta_plot, En, 'r-')\n",
    "ax.plot(theta_plot, Ep, 'r-')\n",
    "ax.plot(theta_plot, E_v, color='dimgray', linestyle='dashed')\n",
    "ax.plot(theta_plot, E_ph, color='dimgray', linestyle='dashed')\n",
    "ax.scatter(theta, LP, color='b',s=20)\n",
    "ax.scatter(theta, UP, color='b', s=20)\n",
    "\n",
    "rabi_text = r'$\\Omega_R = %.2f$' % (Rabi)\n",
    "ax.text(1, 1, rabi_text, bbox=dict(boxstyle='round, pad=0.5', facecolor='white'))\n",
    "ax.set_xlabel(r'$\\theta$ (degrees)')\n",
    "ax.set_ylabel(r'Wavenumber (cm$^{-1}$)')\n",
    "ax.set_title('Dispersion with Fitted Polariton Eigenenergies')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "## Export Data\n",
    "\n",
    "Export polariton fitting data to csv or open the Rabi Splitting Data table and append a new entry."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export dispersion data as .csv and store path in Rabi splitting database for future retrieval\n",
    "\n",
    "export_to = '/export/path/'\n",
    "\n",
    "raw_data = pd.DataFrame({'theta': theta,\n",
    "                        'upper polariton': UP,\n",
    "                        'lower polariton': LP\n",
    "                        })\n",
    "\n",
    "fitted_data = pd.DataFrame({'theta': theta_plot,\n",
    "                            'upper polariton': Ep,\n",
    "                            'lower polariton': En,\n",
    "                            'cavity photon': E_ph,\n",
    "                            'vibration energy': E_v})\n",
    "\n",
    "raw_file = export_to + 'filename.csv'\n",
    "fitted_file = export_to + 'filename_fit.csv'\n",
    "\n",
    "# raw_data.to_csv(raw_file)\n",
    "# fitted_data.to_csv(fitted_file)"
   ]
  },
  {
   "source": [
    "### Congratulations! You made it to the end of your analysis!"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}