{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spectral Analysis for Large Data Sets\n",
    "\n",
    "Author: Garrek Stemo \\\n",
    "Date created: August 31, 2020 \\\n",
    "Institution: Nara Institute of Science and Technology\n",
    "\n",
    "This is an interactive notebook for analyzing relatively large sets of spectral data, specifically tuned for angle-resolved FTIR Fabry-Perot spectra. I initially created a command-line tool to do curve fitting and spectral analysis, but this was cumbersome because of the variability from data set to data set and the need to carefully truncate and set bounds on the data. Interactivity also makes it easier to try different fitting models. The notebook uses the lmfit package, which is a wrapper for SciPy's optimize method. It is much more user-friendly and customizable, making it well-adapted to an interactive programming scheme like this one. Lmfit comes with almost all of the fitting functions one might need to perform analysis, but I have included additional functions in a custom `pmath.py` module. The most important function here is the asymmetric Gaussian, Lorentzian, and Voigt functions. Asymmetric broadening of spectra occurs in a wide range of materials, including crystalline solids, nanoparticles, molecular solids, and liquids. The scheme used here to model asymmetries is described in [Korepanov and Sedlovets, 2018](https://arxiv.org/abs/1804.06083). I also wrote a bunch of functions to pull data from FTIR experiments and transfer matrix simulations in the `polariton_processing.py` module. These functions assume the files are named a certain way and are in a particular format, so check out that module for more detail or write your own.\n",
    "\n",
    "\n",
    "### Import Modules\n",
    "\n",
    "We use the matplotlib widgets framework to generate interactive plots. Make sure you have the appropriate dependencies installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "import numpy as np\n",
    "import lmfit as lm\n",
    "import polariton_processing as pp\n",
    "import pmath\n",
    "\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign 'data_directory' the path to a directory containing your angle-resolved data. Each .csv data file must contain \"deg##.##_\" where the \"##.##\" is an angle, which could be an integer or not. The underscore is necessary, since the program uses this to extract the angle information from the file name. Then specify an output directory where you would like output data to go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_directory = ''\n",
    "output_directory = ''\n",
    "\n",
    "angle_data, absorbance_data = pp.get_angle_data_from_dir(data_directory, convert_units=('um', 'cm-1'))\n",
    "sample, params = pp.get_sample_params(data_directory)\n",
    "\n",
    "# pp.write_angle_spec_to_file(angle_data, sample, output_directory)  # Write the spectrum to a file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Bounds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The spectra, either simulated or experimental, probably spans a large domain of frequencies. Here you can truncate the data to isolate just the peaks you want to analyze. You can visualize the spectrum from whichever angle you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_bound = 1940\n",
    "upper_bound = 2172\n",
    "\n",
    "spectrum = angle_data[0]\n",
    "wavenumber, transmittance = pp.truncate(spectrum[1], spectrum[2], lower_bound, upper_bound)\n",
    "\n",
    "fig1, ax = plt.subplots()\n",
    "\n",
    "ax.plot(wavenumber, transmittance)\n",
    "ax.set_title(\"Set wavenumber bounds\")\n",
    "ax.set_xlabel(r'Wavenumber (cm$^{-1}$)')\n",
    "ax.set_ylabel('Transmittance %')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close(fig1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Model and Parameters\n",
    "\n",
    "Now test the fitting functions available in pmath.py to find the one you would like to use. The lmfit package has lots of built-in functions. You can use these, fitting functions in pmath, or your own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def make_model(params):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the model, make initial guesses for the fit parameters, and apply constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lm.Model(pmath.asym_voigt)\n",
    "init_params = model.make_params(amp=0.1, w_0=2077, gamma=10, a=0.0, m=0.3)\n",
    "\n",
    "init_params['m'].set(min=0.0, max=1.0)\n",
    "init_params['gamma'].set(min=0.0)\n",
    "\n",
    "print('parameter names: {}'.format(model.param_names))\n",
    "print('independent variables: {}'.format(model.independent_vars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_result = model.fit(transmittance, init_params, w=wavenumber)\n",
    "# print(result.fit_report())\n",
    "print(first_result.params.pretty_print())\n",
    "# result.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2, ax = plt.subplots()\n",
    "ax.plot(wavenumber, transmittance, 'bo', markersize=5)\n",
    "ax.plot(wavenumber, first_result.init_fit, 'k--', label='initial fit')\n",
    "ax.plot(wavenumber, first_result.best_fit, 'r-', label='best fit')\n",
    "# ax.vlines(result.params['w1'].value, 0, 0.02, linestyles='dashed', color='blue')\n",
    "ax.vlines(first_result.params['w_0'].value, 0, 0.02, linestyles='dashed', color='blue')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close(fig2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automatically Fit Peaks From Multiple Data Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a good fit for the first peak, go through and fit the rest, using the results from this first spetrum as initial guesses for the rest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guess = first_result.values\n",
    "model = lm.Model(pmath.asym_voigt)\n",
    "num_sets_to_analyze = 10\n",
    "data_sets = []\n",
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for angle in range(num_sets_to_analyze):\n",
    "    wavenumber, transmittance = pp.truncate(angle_data[angle][1], angle_data[angle][2], lower_bound, upper_bound)\n",
    "\n",
    "    params = model.make_params(amp=guess['amp'], \n",
    "                               w_0=guess['w_0'], \n",
    "                               gamma=guess['gamma'], \n",
    "                               a=guess['a'], \n",
    "                               m=guess['m'])\n",
    "\n",
    "    params['m'].set(min=0.0, max=1.0)\n",
    "    params['gamma'].set(min=0.0)\n",
    "    \n",
    "    result = model.fit(transmittance, params, w=wavenumber)\n",
    "    \n",
    "    data_sets.append((wavenumber, transmittance))\n",
    "    results.append(result)\n",
    "    guess = result.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine Data\n",
    "\n",
    "Next we should inspect the results to make sure the fitting procedure worked. It's not feasible to inspect *every* spectrum (I won't stop you!), but you can sample a few and see what they look like by changing the `examine_spectrum` index and generating a plot that will show the actual data (blue dots), the best fit (red), and the initial fit (black dashed line). Since we use the previous best fit for the guess of the next data set, we are essentially plotting the best fit for the current data set alongside the best fit for the previous one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examine_spectrum = 0\n",
    "print(results[examine_spectrum].params.pretty_print())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = results[examine_spectrum]\n",
    "wavenumber, transmittance = data_sets[examine_spectrum]\n",
    "\n",
    "fig3, ax = plt.subplots()\n",
    "\n",
    "ax.plot(wavenumber, transmittance, 'bo', markersize=3, label='raw data')\n",
    "ax.plot(wavenumber, result.init_fit, 'k--', label='initial fit')\n",
    "ax.plot(wavenumber, result.best_fit, 'r-', label='best fit')\n",
    "# ax.vlines(result.params['w1'].value, 0, 0.02, linestyles='dashed', color='blue')\n",
    "ax.vlines(result.params['w_0'].value, 0, 0.03, linestyles='dashed', color='blue')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close(fig3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write Data to File\n",
    "\n",
    "We'll write the data to a .csv file because you might need to do run this a few times and collect the results before analyzing the Rabi splitting parameter, which is coming up next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for r in results:\n",
    "#     print(r.values['w_0'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Rabi Splitting Parameter\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
